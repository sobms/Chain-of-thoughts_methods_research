# Отчёт
В результате проделанной работы были реализованы и протестированы методы Chain-of-Thoughts и Self-consistency method на задачах из датасета GSM8K. Для генерации ответов использовалась большая языковая модель BLOOM176B.

## CoT 
В ходе исследования метода CoT были испробованы три различных файла с подсказками: 

* файл с подсказками, сгенерированный из случайно выбранных задач train выборки датасета GSM8K (1);

* подсказки в виде автоматически сгенерированных «сократовских подвопросов»  выбранные вручную из файла train_socratic.jsonl датасета GSM8K (2);

* подсказки предложенные в статье "J. Wei X. Wang. 2023. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" (3).

Для тестирования методов использовались небольшие подвыборки из тестовой части датасета GSM8K (100-200 экземпляров), так как скорость работы распределённой модели BLOOM
достаточно низкая и составляет около 1-1.5 токена в секунду. 

Результаты тестирования метода CoT, использовавшего первый из предложенных файл с подсказками, оказались довольно слабыми и составили около 3-4% точности. 
Два последующих варианта позволили достичь результатов: 8.457% точности и 11% соответственно. 
Для сравнения в статье "J. Wei X. Wang. 2023. Chain-of-Thought Prompting Elicits Reasoning in Large Language Models"
приводятся следующие результаты для моделей LaMDA 137B и GPT-3 175B. Они достигли на датасете GSM8K при использовании метода CoT результатов:
 14.3% и  46.9% соответственно. В ходе анализа сгенерированных результатов были получены следующие выводы:

* модель довольно неплоха в декомпозиции несложных задач на подшаги;

* модель улавливает отношения между объектами в задачах (например, информацию о том, что количество одного объекта в n раз больше/меньше другого и т д)

* отсутствие строгости в математических вычислениях, то есть модель очень часто допускает ошибки в вычислениях

* модель оказалась не способна составлять по задачам уравнения и решать их

* модель пока не умеет грамотно выстраивать цепочку решения для довольно длинных задач, решение которых состоит из более чем 3 действий.

## Self-consistency method

Идея данного метода состоит в том, что сначала генерируют несколько цепочек рассуждений для заданного условия задачи. 
При этом можно использовать различные виды сэмплирования (temperature,top-k, top-p). 
Далее для каждого сгенерированного результата выбирается итоговый ответ на задачу и из полученного множества ответов выбирается наиболее частый.

Были испробованы два варианта генерации с помощью этого метода:

* с использованием файла подсказок (1) и параметрами сэмплирования: 'temperature': 0.7;

* с использованием файла подсказок (2) и параметрами сэмплирования: 'temperature': 0.5, 'top_k': 40,;

Основная проблема этого метода заключается в скорости его работы. По сравнению с предыдущим методом его скорость работы была в 8-10 раз медленнее.
Поэтому для данного метода были использованы подвыборки только из 100 и 50 элементов соответственно.
Наилучший результат был получен для второго варианта генерации. Точность на нём составила около 8%. При этом из результатов было видно, 
что модель даёт в некоторых задачах верные рассуждения. Однако в отличие от результатов полученных в статье "SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT
REASONING IN LANGUAGE MODELS" в данном исследовании качество этого метода оказалось даже хуже, чем у предыдущего.

Причина этого предположительно в том, что в CoT методе используется сэмплирование c помощью greedy decoding, которое показало результат лучше чем опробованные методы сэмплирования с выбранными параметрами.
Качество этого метода должно значительно улучшиться, если модель будет давать более последовательные ответы на задачи.

